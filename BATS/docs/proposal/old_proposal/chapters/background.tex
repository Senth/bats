\section{Background}
Up to date there has, as we know of, been little research for teammate bots\footnote{A bot is a computer player that
you either can play with or against.}; this is especially true for Real-Time Strategy (RTS) games, where only one
scientific article\cite{abraham_ai_2010} was found. There do however exist other articles\cite{jansen07,taylor08} on the
subject. The bots in these articles neither adapts their behavior nor do they convey their intentions to the human
player through communication. There exists other articles on the subject of teammate bots, independent of genre; Tan and
Cheng writes about teammate bots adapting to other teammate bots\cite{Tan_Cheng_2007, zhou_pucheng_multi-agent_2011};
Simon writes about teammate bots in general\cite{simon07}.

To beat the enemy in an RTS game, as a team or one player, you need a strategy that exploits the enemy's weaknesses as
the time while eliminating your own weaknesses. If your strategy is bad, it does not matter how hard you try to win, you
will still looseâ€”don't try to spike a nail with a feather. Articles on player modeling include complementing the
teammate player's weaknesses\cite{jansen07, houlette03, zhou_pucheng_multi-agent_2011} and finding the enemy's
weaknesses\cite{kabanza_opponent_2010, synnaeve_bayesian_2011, schadd_opponent_2007}.

One article\cite{McGee:2010:RTA:1822348.1822365} mentions something the communication between the human player
and the bot (for any genre); the survey article concludes that ``little or no work'' has been done on ``concept learning
and clustering (\ldots), inferencing, and communication''; we verify this by not finding a single subject on
communication for any genre, let alone RTS games.